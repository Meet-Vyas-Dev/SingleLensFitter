{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f623236",
   "metadata": {},
   "source": [
    "# SingleLensFitter - Complete Documentation and Usage Guide\n",
    "\n",
    "This notebook provides comprehensive documentation for the `SingleLensFitter` class, which is used for modeling and analyzing single-lens gravitational microlensing events.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Basic Usage](#basic-usage)\n",
    "3. [Model Configuration Options](#model-configuration)\n",
    "4. [Advanced Features](#advanced-features)\n",
    "5. [Complete Example with All Features](#complete-example)\n",
    "6. [Template for Your Own Data](#your-data-template)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9582311",
   "metadata": {},
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "The `SingleLensFitter` class fits gravitational microlensing light curves using:\n",
    "- **Point-Source, Point-Lens (PSPL)** model as baseline\n",
    "- Optional **finite source effects** with limb darkening\n",
    "- **Gaussian Process** models for correlated noise\n",
    "- **Mixture models** for outlier rejection\n",
    "- **MCMC sampling** using `emcee` for parameter estimation\n",
    "\n",
    "### Required Parameters\n",
    "The fundamental microlensing parameters are:\n",
    "- **u₀**: Impact parameter (closest approach in Einstein radius units)\n",
    "- **t₀**: Time of closest approach (HJD - 2450000)\n",
    "- **tₑ**: Einstein crossing time (days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1bf98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from SingleLensFitter import SingleLensFitter\n",
    "\n",
    "# Set up matplotlib for inline display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f00baa5",
   "metadata": {},
   "source": [
    "## 2. Basic Usage <a name=\"basic-usage\"></a>\n",
    "\n",
    "### 2.1 Prepare Your Data\n",
    "\n",
    "Data must be organized as a dictionary where:\n",
    "- **Keys**: Dataset names (e.g., observatory names)\n",
    "- **Values**: Tuples of `(time, flux, flux_error)` as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e38f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic microlensing data for demonstration\n",
    "def generate_synthetic_event(t0=7500.0, u0=0.1, tE=30.0, F_source=1000.0, F_blend=500.0, noise_level=20.0, n_points=500):\n",
    "    \"\"\"\n",
    "    Generate synthetic microlensing light curve.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    t0 : float\n",
    "        Time of closest approach\n",
    "    u0 : float\n",
    "        Impact parameter\n",
    "    tE : float\n",
    "        Einstein crossing time\n",
    "    F_source : float\n",
    "        Source flux\n",
    "    F_blend : float\n",
    "        Blend flux\n",
    "    noise_level : float\n",
    "        Standard deviation of Gaussian noise\n",
    "    n_points : int\n",
    "        Number of data points\n",
    "    \"\"\"\n",
    "    time = np.linspace(t0 - 2 * tE, t0 + 2 * tE, n_points)\n",
    "    tau = (time - t0) / tE\n",
    "    u = np.sqrt(u0**2 + tau**2)\n",
    "    magnification = (u**2 + 2) / (u * np.sqrt(u**2 + 4))\n",
    "    \n",
    "    flux = F_source * magnification + F_blend\n",
    "    flux += np.random.normal(0, noise_level, len(time))\n",
    "    err = np.ones_like(flux) * noise_level\n",
    "    \n",
    "    return time, flux, err\n",
    "\n",
    "# Generate data for a single observatory\n",
    "time, flux, err = generate_synthetic_event()\n",
    "data_dict = {'Observatory1': (time, flux, err)}\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(time, flux, yerr=err, fmt='.', alpha=0.6, label='Observatory1')\n",
    "plt.xlabel('Time (HJD - 2450000)')\n",
    "plt.ylabel('Flux')\n",
    "plt.title('Synthetic Microlensing Event')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d7e82",
   "metadata": {},
   "source": [
    "### 2.2 Initialize the Fitter\n",
    "\n",
    "Provide initial parameter guesses: `[u0, t0, tE]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61439182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial parameter guesses\n",
    "initial_params = np.array([0.15, 7505.0, 25.0])  # [u0, t0, tE]\n",
    "\n",
    "# Initialize the fitter\n",
    "fitter = SingleLensFitter(\n",
    "    data=data_dict,\n",
    "    initial_parameters=initial_params,\n",
    "    ZP=28.0  # Magnitude zero-point for plotting\n",
    ")\n",
    "\n",
    "print(f\"Initialized fitter with {fitter.ndim} parameters\")\n",
    "print(f\"Parameter labels: {fitter.parameter_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1253dd",
   "metadata": {},
   "source": [
    "### 2.3 Run a Simple Fit\n",
    "\n",
    "Use optimization to find the best-fit parameters quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick optimization (useful for finding starting point)\n",
    "fitter.fit(method='Nelder-Mead')\n",
    "\n",
    "print(f\"\\nOptimized parameters:\")\n",
    "print(f\"u0 = {fitter.p[0]:.4f}\")\n",
    "print(f\"t0 = {fitter.p[1]:.4f}\")\n",
    "print(f\"tE = {fitter.p[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bd4a37",
   "metadata": {},
   "source": [
    "## 3. Model Configuration Options <a name=\"model-configuration\"></a>\n",
    "\n",
    "### 3.1 Finite Source Effects\n",
    "\n",
    "Add finite source effects when the source size is comparable to the Einstein radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a32333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new fitter instance\n",
    "fitter_fs = SingleLensFitter(\n",
    "    data=data_dict,\n",
    "    initial_parameters=initial_params\n",
    ")\n",
    "\n",
    "# Add finite source effects\n",
    "fitter_fs.add_finite_source(lrho=-3.0)  # log10(rho), where rho = R_*/R_E\n",
    "\n",
    "print(f\"Number of parameters with finite source: {fitter_fs.ndim}\")\n",
    "print(f\"Parameter labels: {fitter_fs.parameter_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3c39e",
   "metadata": {},
   "source": [
    "### 3.2 Limb Darkening\n",
    "\n",
    "Add linear limb darkening (automatically includes finite source effects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new fitter instance\n",
    "fitter_ld = SingleLensFitter(\n",
    "    data=data_dict,\n",
    "    initial_parameters=initial_params\n",
    ")\n",
    "\n",
    "# Add limb darkening (includes finite source automatically)\n",
    "fitter_ld.add_limb_darkening(\n",
    "    gamma=0.5,   # Linear limb-darkening coefficient (0-1)\n",
    "    lrho=-2.5    # log10(source radius)\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters with limb darkening: {fitter_ld.ndim}\")\n",
    "print(f\"Parameter labels: {fitter_ld.parameter_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ddbec7",
   "metadata": {},
   "source": [
    "### 3.3 Source Variability\n",
    "\n",
    "Model sinusoidal variability in the source star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388a984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new fitter instance\n",
    "fitter_sv = SingleLensFitter(\n",
    "    data=data_dict,\n",
    "    initial_parameters=initial_params\n",
    ")\n",
    "\n",
    "# Add source variability: F_source * (1 + K*sin(omega*t + phi))\n",
    "fitter_sv.add_source_variability(\n",
    "    params=(0.001, np.pi, 0.0)  # (K, omega, phi)\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters with source variability: {fitter_sv.ndim}\")\n",
    "print(f\"Parameter labels: {fitter_sv.parameter_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85298ab5",
   "metadata": {},
   "source": [
    "### 3.4 Blend Variability\n",
    "\n",
    "Model sinusoidal variability in the blend flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afc686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new fitter instance\n",
    "fitter_bv = SingleLensFitter(\n",
    "    data=data_dict,\n",
    "    initial_parameters=initial_params\n",
    ")\n",
    "\n",
    "# Add blend variability: F_blend * (1 + K*sin(omega*t + phi))\n",
    "fitter_bv.add_blend_variability(\n",
    "    params=(0.001, np.pi, 0.0)  # (K, omega, phi)\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters with blend variability: {fitter_bv.ndim}\")\n",
    "print(f\"Parameter labels: {fitter_bv.parameter_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1324185d",
   "metadata": {},
   "source": [
    "### 3.5 Gaussian Process Model\n",
    "\n",
    "Model correlated noise using a Gaussian Process with an exponential kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd106a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using fast linear fit for quick testing\n",
    "\n",
    "# Generate simple test data\n",
    "time_fast, flux_fast, err_fast = generate_synthetic_event(\n",
    "    t0=7500, u0=0.2, tE=25, noise_level=15, n_points=1000\n",
    ")\n",
    "data_fast = {'QuickTest': (time_fast, flux_fast, err_fast)}\n",
    "\n",
    "# Initialize with simple PSPL model\n",
    "fitter_fast = SingleLensFitter(\n",
    "    data=data_fast,\n",
    "    initial_parameters=np.array([0.25, 7502, 23])\n",
    ")\n",
    "\n",
    "# Enable fast linear fit\n",
    "fitter_fast.use_fast_linear_fit = True\n",
    "\n",
    "# Configure for quick test\n",
    "fitter_fast.nwalkers = 30\n",
    "fitter_fast.nsteps_production = 200\n",
    "fitter_fast.plotprefix = 'fast_fit_test'\n",
    "\n",
    "print(\"Fast linear fit enabled: \", fitter_fast.use_fast_linear_fit)\n",
    "print(\"This will use lightweight weighted least squares instead of full matrix inversion.\")\n",
    "print(\"\\nRunning quick optimization...\")\n",
    "\n",
    "# Quick optimization\n",
    "fitter_fast.fit(method='Nelder-Mead')\n",
    "\n",
    "print(f\"\\nOptimized parameters:\")\n",
    "print(f\"  u0 = {fitter_fast.p[0]:.4f}\")\n",
    "print(f\"  t0 = {fitter_fast.p[1]:.4f}\")\n",
    "print(f\"  tE = {fitter_fast.p[2]:.4f}\")\n",
    "\n",
    "# Note: For MCMC sampling, the fast fit will be used automatically\n",
    "# fitter_fast.sample(optimize_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4688da28",
   "metadata": {},
   "source": [
    "### 3.6 Eigen Lightcurves (Detrending Vectors)\n",
    "\n",
    "Eigen lightcurves are pre-computed basis vectors used to model and remove systematic effects in the data. This is particularly useful for removing trends caused by:\n",
    "- Atmospheric variations\n",
    "- Instrumental drifts\n",
    "- Seeing variations\n",
    "- Background contamination\n",
    "- Any other systematic effect that can be modeled linearly\n",
    "\n",
    "**How it works**:\n",
    "1. Create eigen vectors (basis functions) from your data or external sources\n",
    "2. The fitter linearly combines these vectors to model systematic trends\n",
    "3. The trend is fitted simultaneously with the microlensing signal\n",
    "4. Different observatories can have different sets of eigen lightcurves\n",
    "\n",
    "**Common sources of eigen lightcurves**:\n",
    "- Principal Component Analysis (PCA) of reference stars\n",
    "- Time-dependent PSF models\n",
    "- Known instrumental systematics\n",
    "- Environmental monitors (temperature, humidity, etc.)\n",
    "\n",
    "**Mathematical model**:\n",
    "For each observatory, the flux is modeled as:\n",
    "\n",
    "$$F(t) = F_s \\cdot A(t) + F_b + \\sum_{i=1}^{N_{eigen}} c_i \\cdot E_i(t)$$\n",
    "\n",
    "Where:\n",
    "- $F_s$ = source flux\n",
    "- $A(t)$ = magnification\n",
    "- $F_b$ = blend flux\n",
    "- $c_i$ = eigen lightcurve coefficients (fitted parameters)\n",
    "- $E_i(t)$ = eigen lightcurve basis vectors (provided by user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0cf411",
   "metadata": {},
   "source": [
    "### Creating Eigen Lightcurves from Your Data\n",
    "\n",
    "**Method 1: Principal Component Analysis (PCA) from Reference Stars**\n",
    "\n",
    "If you have reference stars (non-variable stars in the same field), you can use PCA to extract systematic trends:\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assume you have reference star light curves: ref_stars (n_stars × n_times)\n",
    "# Each row is a different reference star, each column is a time point\n",
    "\n",
    "# Subtract the mean from each reference star\n",
    "ref_stars_centered = ref_stars - np.mean(ref_stars, axis=1, keepdims=True)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=3)  # Extract 3 principal components\n",
    "pca.fit(ref_stars_centered.T)  # Fit on transposed data\n",
    "\n",
    "# Get the principal components (eigen lightcurves)\n",
    "eigen_lcs = pca.components_  # Shape: (3, n_times)\n",
    "\n",
    "# These eigen lightcurves capture the dominant systematic variations\n",
    "```\n",
    "\n",
    "**Method 2: Known Instrumental Effects**\n",
    "\n",
    "If you know specific instrumental or environmental effects:\n",
    "\n",
    "```python\n",
    "# Example: Temperature-dependent drift\n",
    "temperature_curve = temperature_data  # From observatory logs\n",
    "eigen_lc_temp = (temperature_curve - np.mean(temperature_curve)) / np.std(temperature_curve)\n",
    "\n",
    "# Example: Airmass correction\n",
    "airmass_curve = compute_airmass(time, target_coords, observatory_location)\n",
    "eigen_lc_airmass = airmass_curve - np.mean(airmass_curve)\n",
    "\n",
    "# Combine into eigen lightcurve array\n",
    "eigen_lcs = np.vstack([eigen_lc_temp, eigen_lc_airmass])\n",
    "```\n",
    "\n",
    "**Method 3: Polynomial Detrending**\n",
    "\n",
    "For simple time-dependent trends:\n",
    "\n",
    "```python\n",
    "# Create polynomial basis functions\n",
    "time_normalized = (time - np.mean(time)) / np.std(time)\n",
    "eigen_lc_linear = time_normalized\n",
    "eigen_lc_quadratic = time_normalized ** 2\n",
    "eigen_lc_cubic = time_normalized ** 3\n",
    "\n",
    "eigen_lcs = np.vstack([eigen_lc_linear, eigen_lc_quadratic, eigen_lc_cubic])\n",
    "```\n",
    "\n",
    "**Important**: Always normalize your eigen lightcurves to have zero mean and unit variance for numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Using eigen lightcurves for detrending\n",
    "\n",
    "# Generate data with a systematic trend\n",
    "time_trend, flux_trend, err_trend = generate_synthetic_event(\n",
    "    t0=7500, u0=0.15, tE=28, F_source=1000, F_blend=500, \n",
    "    noise_level=18, n_points=500\n",
    ")\n",
    "\n",
    "# Add a systematic trend (e.g., instrumental drift)\n",
    "# This could be atmospheric effects, temperature drift, etc.\n",
    "systematic_trend_1 = 50 * np.sin(2 * np.pi * time_trend / 20)  # ~20-day oscillation\n",
    "systematic_trend_2 = 30 * np.exp(-(time_trend - 7500)**2 / (2 * 50**2))  # Gaussian bump\n",
    "\n",
    "# Add systematics to the flux\n",
    "flux_with_systematics = flux_trend + systematic_trend_1 + systematic_trend_2\n",
    "\n",
    "# Create eigen lightcurves (basis vectors for detrending)\n",
    "# In practice, these would come from PCA of reference stars or other analysis\n",
    "# Here we'll create them to match our known systematics\n",
    "eigen_lc_1 = np.sin(2 * np.pi * time_trend / 20)  # Sinusoidal component\n",
    "eigen_lc_2 = np.exp(-(time_trend - 7500)**2 / (2 * 50**2))  # Gaussian component\n",
    "eigen_lc_3 = np.ones_like(time_trend)  # Constant offset (optional)\n",
    "\n",
    "# Stack into an array: shape is (n_eigen_vectors, n_data_points)\n",
    "eigen_lightcurves_array = np.vstack([eigen_lc_1, eigen_lc_2, eigen_lc_3])\n",
    "\n",
    "print(f\"Created {eigen_lightcurves_array.shape[0]} eigen lightcurves\")\n",
    "print(f\"Each has {eigen_lightcurves_array.shape[1]} data points\")\n",
    "\n",
    "# Create data dictionary\n",
    "data_with_eigen = {'Observatory_A': (time_trend, flux_with_systematics, err_trend)}\n",
    "\n",
    "# Create eigen lightcurves dictionary\n",
    "# Keys must match the data dictionary keys\n",
    "eigen_lcs_dict = {'Observatory_A': eigen_lightcurves_array}\n",
    "\n",
    "# Initialize fitter WITH eigen lightcurves\n",
    "fitter_eigen = SingleLensFitter(\n",
    "    data=data_with_eigen,\n",
    "    initial_parameters=np.array([0.18, 7502, 26]),\n",
    "    eigen_lightcurves=eigen_lcs_dict  # Pass eigen lightcurves here\n",
    ")\n",
    "\n",
    "print(f\"\\nFitter initialized with eigen lightcurves for detrending\")\n",
    "print(f\"Number of microlensing parameters: 3 (u0, t0, tE)\")\n",
    "print(f\"Number of linear parameters per observatory: 2 (Fs, Fb) + {eigen_lightcurves_array.shape[0]} (eigen coeffs)\")\n",
    "print(f\"The eigen coefficients will be marginalized over during fitting\")\n",
    "\n",
    "# Configure and optimize\n",
    "fitter_eigen.plotprefix = 'eigen_detrend_test'\n",
    "fitter_eigen.nwalkers = 40\n",
    "fitter_eigen.nsteps_production = 300\n",
    "\n",
    "print(\"\\nRunning optimization...\")\n",
    "fitter_eigen.fit(method='Nelder-Mead')\n",
    "\n",
    "print(f\"\\nOptimized microlensing parameters:\")\n",
    "print(f\"  u0 = {fitter_eigen.p[0]:.4f}\")\n",
    "print(f\"  t0 = {fitter_eigen.p[1]:.4f}\")\n",
    "print(f\"  tE = {fitter_eigen.p[2]:.4f}\")\n",
    "\n",
    "print(\"\\nThe systematic trends have been removed by fitting the eigen lightcurves!\")\n",
    "print(\"The eigen coefficients are automatically marginalized over in the likelihood.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46630aaa",
   "metadata": {},
   "source": [
    "### 3.7 Fast Linear Fit Optimization\n",
    "\n",
    "For simple PSPL models without advanced features, you can enable a lightweight linear fitting routine that is faster than the full matrix inversion method.\n",
    "\n",
    "**When to use `use_fast_linear_fit`**:\n",
    "- ✅ Simple PSPL model (only u₀, t₀, tₑ parameters)\n",
    "- ✅ Blended model (fitting both source and blend flux)\n",
    "- ✅ Quick testing or exploratory analysis\n",
    "- ✅ Large datasets where speed is critical\n",
    "\n",
    "**When NOT to use it**:\n",
    "- ❌ Gaussian Process models\n",
    "- ❌ Eigen lightcurves (detrending)\n",
    "- ❌ Source or blend variability\n",
    "- ❌ Mixture models\n",
    "- ❌ Non-blended models\n",
    "\n",
    "**Performance gain**: Typically 2-5× faster for simple models with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa251ba",
   "metadata": {},
   "source": [
    "**Multi-Observatory Eigen Lightcurves**:\n",
    "\n",
    "Different observatories can have different systematic effects, so you can provide different eigen lightcurves for each:\n",
    "\n",
    "```python\n",
    "# Example structure for multi-observatory eigen lightcurves\n",
    "eigen_lcs_multi = {\n",
    "    'OGLE': eigen_array_ogle,      # shape: (n_eigen_ogle, n_points_ogle)\n",
    "    'MOA': eigen_array_moa,         # shape: (n_eigen_moa, n_points_moa)\n",
    "    'KMTNet': eigen_array_kmtnet    # shape: (n_eigen_kmtnet, n_points_kmtnet)\n",
    "}\n",
    "\n",
    "# Not all observatories need eigen lightcurves\n",
    "eigen_lcs_partial = {\n",
    "    'OGLE': eigen_array_ogle,  # OGLE has systematics to remove\n",
    "    # MOA and KMTNet don't have eigen lightcurves - will use standard fitting\n",
    "}\n",
    "```\n",
    "\n",
    "**Best Practices**:\n",
    "1. **Orthogonalize**: Use PCA or Gram-Schmidt to create orthogonal basis vectors\n",
    "2. **Normalization**: Normalize eigen vectors to have similar amplitudes\n",
    "3. **Number of vectors**: Use 2-5 eigen lightcurves; too many can cause overfitting\n",
    "4. **Validation**: Test with simulated data to ensure systematics are properly removed\n",
    "5. **Physical meaning**: If possible, relate eigen vectors to known physical effects\n",
    "\n",
    "**Technical Notes**:\n",
    "- Eigen coefficients are treated as **nuisance parameters** and are marginalized over analytically\n",
    "- This is computationally efficient - no MCMC sampling needed for eigen coefficients\n",
    "- The marginalization is done during the linear fit using matrix algebra\n",
    "- Eigen lightcurves increase the size of the design matrix but not the MCMC dimensionality\n",
    "- Incompatible with `use_fast_linear_fit` (requires full matrix inversion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b9b44",
   "metadata": {},
   "source": [
    "### Implementation Details: Fast Linear Fit vs Full Linear Fit\n",
    "\n",
    "**Understanding the Two Approaches**:\n",
    "\n",
    "The `SingleLensFitter` has two methods for fitting linear parameters (source flux, blend flux, eigen coefficients):\n",
    "\n",
    "#### 1. Full Linear Fit (`linear_fit_full`)\n",
    "- **Method**: Cholesky decomposition with full covariance matrix inversion\n",
    "- **Handles**: All features (GP, eigen lightcurves, variability, mixture models)\n",
    "- **Mathematics**: \n",
    "  - Constructs design matrix **A** (magnification, eigen vectors, etc.)\n",
    "  - Builds covariance matrix **C** (including GP correlations if used)\n",
    "  - Solves: **S** = **A**ᵀ **C**⁻¹ **A**, **b** = **A**ᵀ **C**⁻¹ **y**\n",
    "  - Parameters: **θ** = **S**⁻¹ **b**\n",
    "  - Can marginalize over linear parameters analytically\n",
    "- **Cost**: O(N³) for matrix inversion, where N = number of data points\n",
    "\n",
    "#### 2. Fast Linear Fit (`linear_fit_fast`)\n",
    "- **Method**: Weighted least squares without full matrix construction\n",
    "- **Handles**: Simple PSPL only (no GP, no eigen lightcurves, no variability)\n",
    "- **Mathematics**:\n",
    "  - Design matrix: **A** = [**1**, **mag**]ᵀ (only constant and magnification)\n",
    "  - Diagonal weights: **w** = 1/σ²\n",
    "  - Solves: **S** = **A** diag(**w**) **A**ᵀ, **b** = **A** diag(**w**) **y**\n",
    "  - Parameters: [F_blend, F_source] = **S**⁻¹ **b**\n",
    "- **Cost**: O(N) - no full matrix inversion, just a 2×2 system\n",
    "- **Speedup**: 2-5× faster for large datasets\n",
    "\n",
    "**When is Fast Fit Used?**\n",
    "\n",
    "The code automatically selects the fast fit when:\n",
    "```python\n",
    "can_use_fast_fit = (\n",
    "    self.use_fast_linear_fit and                    # User enabled it\n",
    "    not self.use_gaussian_process_model and         # No GP\n",
    "    (self.eigen_lightcurves is None or              # No eigen lightcurves\n",
    "     data_key not in self.eigen_lightcurves) and\n",
    "    not self.use_source_variability and             # No source variability\n",
    "    not self.use_blend_variability and              # No blend variability\n",
    "    not self.use_mixture_model and                  # No mixture model\n",
    "    self.fit_blended                                # Must fit both Fs and Fb\n",
    ")\n",
    "```\n",
    "\n",
    "**Example from Source Code** (SingleLensFitter.py):\n",
    "```python\n",
    "def linear_fit_fast(self, data_key, mag):\n",
    "    \"\"\"Lightweight linear fit for simple models.\"\"\"\n",
    "    t, y, yerr = self.data[data_key]\n",
    "    w = 1.0 / (yerr ** 2)\n",
    "    A = np.vstack((np.ones_like(mag), mag))\n",
    "    Aw = A * w\n",
    "    Sw = Aw @ A.T                    # 2×2 matrix\n",
    "    bw = Aw @ y\n",
    "    a = np.linalg.solve(Sw, bw)      # Fast 2×2 solve\n",
    "    model = a[0] + a[1] * mag\n",
    "    chi2 = np.sum(((y - model) / yerr) ** 2)\n",
    "    return a, -0.5 * chi2\n",
    "```\n",
    "\n",
    "**Recommendation**: Use fast fit for quick testing, but use full fit for production runs with complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new fitter instance\n",
    "fitter_gp = SingleLensFitter(\n",
    "    data=data_dict,\n",
    "    initial_parameters=initial_params\n",
    ")\n",
    "\n",
    "# Add Gaussian Process model\n",
    "fitter_gp.add_gaussian_process_model(\n",
    "    common=True  # Use same GP parameters for all datasets\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters with GP model: {fitter_gp.ndim}\")\n",
    "print(f\"Parameter labels: {fitter_gp.parameter_labels}\")\n",
    "print(f\"\\nGP parameters: ln_a (log amplitude), ln_tau (log timescale)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422eb77c",
   "metadata": {},
   "source": [
    "### 3.8 Mixture Model for Outlier Rejection\n",
    "\n",
    "Add a mixture model to handle outliers robustly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new fitter instance\n",
    "fitter_mm = SingleLensFitter(\n",
    "    data=data_dict,\n",
    "    initial_parameters=initial_params\n",
    ")\n",
    "\n",
    "# Add mixture model\n",
    "fitter_mm.add_mixture_model()\n",
    "\n",
    "print(f\"Number of parameters with mixture model: {fitter_mm.ndim}\")\n",
    "print(f\"Parameter labels: {fitter_mm.parameter_labels}\")\n",
    "print(f\"\\nMixture model parameters per dataset:\")\n",
    "print(f\"  P_b: Outlier probability\")\n",
    "print(f\"  V_b: Outlier variance\")\n",
    "print(f\"  Y_b: Outlier mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51316eb3",
   "metadata": {},
   "source": [
    "## 4. Advanced Features <a name=\"advanced-features\"></a>\n",
    "\n",
    "### 4.1 Multi-Dataset Fitting\n",
    "\n",
    "Fit data from multiple observatories simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce667d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data from multiple observatories\n",
    "time1, flux1, err1 = generate_synthetic_event(t0=7500, u0=0.1, tE=30, noise_level=20)\n",
    "time2, flux2, err2 = generate_synthetic_event(t0=7500, u0=0.1, tE=30, F_source=1500, F_blend=300, noise_level=25)\n",
    "time3, flux3, err3 = generate_synthetic_event(t0=7500, u0=0.1, tE=30, F_source=800, F_blend=600, noise_level=15, n_points=400)\n",
    "\n",
    "# Create multi-dataset dictionary\n",
    "multi_data = {\n",
    "    'OGLE': (time1, flux1, err1),\n",
    "    'MOA': (time2, flux2, err2),\n",
    "    'KMTNet': (time3, flux3, err3)\n",
    "}\n",
    "\n",
    "# Visualize all datasets\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = ['red', 'blue', 'green']\n",
    "for i, (name, (t, f, e)) in enumerate(multi_data.items()):\n",
    "    plt.errorbar(t, f, yerr=e, fmt='.', alpha=0.5, color=colors[i], label=name)\n",
    "plt.xlabel('Time (HJD - 2450000)')\n",
    "plt.ylabel('Flux')\n",
    "plt.title('Multi-Observatory Microlensing Event')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Initialize fitter with multiple datasets\n",
    "fitter_multi = SingleLensFitter(\n",
    "    data=multi_data,\n",
    "    initial_parameters=initial_params,\n",
    "    reference_source='OGLE'  # Use OGLE as reference for combined plots\n",
    ")\n",
    "\n",
    "print(f\"Fitting {len(multi_data)} datasets simultaneously\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872da3a5",
   "metadata": {},
   "source": [
    "### 4.2 Configuring MCMC Settings\n",
    "\n",
    "Customize the MCMC sampler parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a45529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MCMC settings\n",
    "fitter_multi.nwalkers = 50                  # Number of MCMC walkers\n",
    "fitter_multi.nsteps = 100                   # Steps per burn-in iteration\n",
    "fitter_multi.nsteps_production = 500        # Steps in production run\n",
    "fitter_multi.max_burnin_iterations = 50     # Maximum burn-in iterations\n",
    "\n",
    "# Convergence thresholds\n",
    "fitter_multi.emcee_lnp_convergence_threshold = 0.5\n",
    "fitter_multi.emcee_mean_convergence_threshold = 0.1\n",
    "fitter_multi.emcee_std_convergence_threshold = 0.1\n",
    "\n",
    "# Output settings\n",
    "fitter_multi.plotprefix = 'multi_obs_fit'\n",
    "fitter_multi.make_plots = True\n",
    "fitter_multi.n_plot_samples = 30            # Number of posterior samples to plot\n",
    "\n",
    "print(\"MCMC configuration:\")\n",
    "print(f\"  Walkers: {fitter_multi.nwalkers}\")\n",
    "print(f\"  Burn-in steps: {fitter_multi.nsteps}\")\n",
    "print(f\"  Production steps: {fitter_multi.nsteps_production}\")\n",
    "print(f\"  Output prefix: {fitter_multi.plotprefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc8ddc6",
   "metadata": {},
   "source": [
    "### 4.3 Setting Parameter Limits\n",
    "\n",
    "Customize the prior ranges for parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6d177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set custom parameter limits (priors)\n",
    "fitter_multi.u0_limits = (0.0, 1.0)         # Impact parameter range\n",
    "fitter_multi.t0_limits = (7400, 7600)       # Time of closest approach range\n",
    "fitter_multi.tE_limits = (10, 100)          # Einstein crossing time range\n",
    "\n",
    "# For finite source models\n",
    "fitter_multi.lrho_limits = (-6, 0)          # log10(rho) range\n",
    "\n",
    "# For Gaussian Process models\n",
    "fitter_multi.ln_a_limits = (-5, 15)         # GP amplitude range\n",
    "fitter_multi.ln_tau_limits = (-5.5, 7.0)    # GP timescale range\n",
    "\n",
    "print(\"Parameter limits set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef06fa25",
   "metadata": {},
   "source": [
    "## 5. Complete Example with All Features <a name=\"complete-example\"></a>\n",
    "\n",
    "This example demonstrates a full analysis pipeline with multiple model components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1707dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive fitter with multiple features\n",
    "print(\"Setting up comprehensive model...\\n\")\n",
    "\n",
    "fitter_full = SingleLensFitter(\n",
    "    data=multi_data,\n",
    "    initial_parameters=np.array([0.12, 7498.0, 28.0]),\n",
    "    reference_source='OGLE',\n",
    "    ZP=28.0\n",
    ")\n",
    "\n",
    "# Add model complexity\n",
    "print(\"Adding model components:\")\n",
    "print(\"  - Finite source with limb darkening\")\n",
    "fitter_full.add_limb_darkening(gamma=0.5, lrho=-2.5)\n",
    "\n",
    "print(\"  - Gaussian Process for correlated noise\")\n",
    "fitter_full.add_gaussian_process_model(common=True)\n",
    "\n",
    "# Configure MCMC (shorter run for demo)\n",
    "fitter_full.nwalkers = 50\n",
    "fitter_full.nsteps = 50\n",
    "fitter_full.nsteps_production = 200\n",
    "fitter_full.max_burnin_iterations = 10\n",
    "fitter_full.plotprefix = 'example_full_fit'\n",
    "fitter_full.make_plots = True\n",
    "\n",
    "print(f\"\\nTotal parameters to fit: {fitter_full.ndim}\")\n",
    "print(f\"Parameters: {fitter_full.parameter_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the MCMC sampler\n",
    "print(\"Running MCMC sampler...\\n\")\n",
    "print(\"This may take several minutes...\\n\")\n",
    "\n",
    "# Note: Set optimize_first=True to find a good starting point\n",
    "fitter_full.sample(optimize_first=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MCMC SAMPLING COMPLETE\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b43b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"\\nFinal Results:\")\n",
    "print(\"=\"*50)\n",
    "for i, label in enumerate(fitter_full.parameter_labels):\n",
    "    print(f\"{label}: {fitter_full.p[i]:.6f}\")\n",
    "\n",
    "print(\"\\nOutput files generated:\")\n",
    "print(f\"  - {fitter_full.plotprefix}.fit_results\")\n",
    "print(f\"  - {fitter_full.plotprefix}-combined-lightcurve.png\")\n",
    "print(f\"  - {fitter_full.plotprefix}-lc.png\")\n",
    "print(f\"  - {fitter_full.plotprefix}-pdist.png\")\n",
    "print(f\"  - {fitter_full.plotprefix}-burnin.png\")\n",
    "print(f\"  - {fitter_full.plotprefix}-final.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b24e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated plots\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "\n",
    "plot_files = [\n",
    "    f\"{fitter_full.plotprefix}-combined-lightcurve.png\",\n",
    "    f\"{fitter_full.plotprefix}-pdist.png\",\n",
    "    f\"{fitter_full.plotprefix}-final.png\"\n",
    "]\n",
    "\n",
    "for plot_file in plot_files:\n",
    "    if os.path.exists(plot_file):\n",
    "        print(f\"\\n{plot_file}:\")\n",
    "        display(Image(filename=plot_file))\n",
    "    else:\n",
    "        print(f\"\\n{plot_file}: Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50ab97",
   "metadata": {},
   "source": [
    "## 6. Template for Your Own Data <a name=\"your-data-template\"></a>\n",
    "\n",
    "Use this template to analyze your own microlensing data. Simply modify the data loading section to read your files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a54901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TEMPLATE: Analyze Your Own Microlensing Data\n",
    "# ============================================================================\n",
    "\n",
    "# STEP 1: Load your data\n",
    "# Replace this section with code to load your actual data files\n",
    "# Your data should have columns: time, flux, flux_error\n",
    "\n",
    "def load_your_data():\n",
    "    \"\"\"\n",
    "    Load microlensing data from your files.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    data_dict : dict\n",
    "        Dictionary with observatory names as keys and (time, flux, error) tuples as values\n",
    "    \"\"\"\n",
    "    \n",
    "    # Example: Loading from text files\n",
    "    # Uncomment and modify for your data format\n",
    "    \n",
    "    # Option 1: Single file with multiple columns\n",
    "    # data = np.loadtxt('my_lightcurve.dat')\n",
    "    # time, flux, flux_err = data[:, 0], data[:, 1], data[:, 2]\n",
    "    # data_dict = {'MyTelescope': (time, flux, flux_err)}\n",
    "    \n",
    "    # Option 2: Multiple files from different observatories\n",
    "    # ogle_data = np.loadtxt('ogle_data.txt')\n",
    "    # moa_data = np.loadtxt('moa_data.txt')\n",
    "    # data_dict = {\n",
    "    #     'OGLE': (ogle_data[:, 0], ogle_data[:, 1], ogle_data[:, 2]),\n",
    "    #     'MOA': (moa_data[:, 0], moa_data[:, 1], moa_data[:, 2])\n",
    "    # }\n",
    "    \n",
    "    # Option 3: CSV files with pandas\n",
    "    # import pandas as pd\n",
    "    # df = pd.read_csv('my_data.csv')\n",
    "    # data_dict = {'Survey': (df['time'].values, df['flux'].values, df['error'].values)}\n",
    "    \n",
    "    # For this template, we'll use synthetic data\n",
    "    print(\"Using synthetic data for demonstration.\")\n",
    "    print(\"Replace this function with your actual data loading code.\\n\")\n",
    "    \n",
    "    time, flux, err = generate_synthetic_event(\n",
    "        t0=7500.0, u0=0.1, tE=30.0,\n",
    "        F_source=1000.0, F_blend=500.0,\n",
    "        noise_level=20.0, n_points=500\n",
    "    )\n",
    "    \n",
    "    return {'YourObservatory': (time, flux, err)}\n",
    "\n",
    "# Load data\n",
    "your_data = load_your_data()\n",
    "print(f\"Loaded data from {len(your_data)} observatory/observatories\")\n",
    "for name, (t, f, e) in your_data.items():\n",
    "    print(f\"  {name}: {len(t)} data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b2137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Set initial parameter estimates\n",
    "# Examine your light curve and estimate:\n",
    "#   u0: Impact parameter (typically 0.01 - 1.0)\n",
    "#   t0: Time of peak magnification (inspect your light curve)\n",
    "#   tE: Duration of event in days (full width ~ 2*tE)\n",
    "\n",
    "initial_u0 = 0.1      # Impact parameter estimate\n",
    "initial_t0 = 7500.0   # Time of peak (HJD - 2450000)\n",
    "initial_tE = 30.0     # Event duration estimate\n",
    "\n",
    "your_initial_params = np.array([initial_u0, initial_t0, initial_tE])\n",
    "\n",
    "print(f\"Initial parameter guesses:\")\n",
    "print(f\"  u0 = {initial_u0}\")\n",
    "print(f\"  t0 = {initial_t0}\")\n",
    "print(f\"  tE = {initial_tE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Initialize the fitter\n",
    "your_fitter = SingleLensFitter(\n",
    "    data=your_data,\n",
    "    initial_parameters=your_initial_params,\n",
    "    reference_source=list(your_data.keys())[0],  # First observatory as reference\n",
    "    ZP=28.0  # Adjust if needed for your photometric system\n",
    ")\n",
    "\n",
    "print(f\"Fitter initialized with {your_fitter.ndim} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6795da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Add model components (customize based on your needs)\n",
    "\n",
    "# Uncomment the features you want to include:\n",
    "\n",
    "# Add finite source effects (for high magnification events)\n",
    "# your_fitter.add_finite_source(lrho=-3.0)\n",
    "\n",
    "# Add limb darkening (includes finite source)\n",
    "# your_fitter.add_limb_darkening(gamma=0.5, lrho=-2.5)\n",
    "\n",
    "# Add source variability\n",
    "# your_fitter.add_source_variability(params=(0.001, np.pi, 0.0))\n",
    "\n",
    "# Add blend variability\n",
    "# your_fitter.add_blend_variability(params=(0.001, np.pi, 0.0))\n",
    "\n",
    "# Add Gaussian Process for correlated noise\n",
    "# your_fitter.add_gaussian_process_model(common=True)\n",
    "\n",
    "# Add mixture model for outlier rejection\n",
    "# your_fitter.add_mixture_model()\n",
    "\n",
    "print(f\"Model configured with {your_fitter.ndim} parameters\")\n",
    "print(f\"Parameters: {your_fitter.parameter_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Configure MCMC settings\n",
    "\n",
    "# For quick testing (low accuracy)\n",
    "your_fitter.nwalkers = 50\n",
    "your_fitter.nsteps = 100\n",
    "your_fitter.nsteps_production = 500\n",
    "your_fitter.max_burnin_iterations = 20\n",
    "\n",
    "# For publication-quality results, increase these values:\n",
    "# your_fitter.nwalkers = 100\n",
    "# your_fitter.nsteps = 200\n",
    "# your_fitter.nsteps_production = 2000\n",
    "# your_fitter.max_burnin_iterations = 100\n",
    "\n",
    "# Set output file prefix\n",
    "your_fitter.plotprefix = 'my_event_fit'\n",
    "your_fitter.make_plots = True\n",
    "\n",
    "print(\"MCMC settings configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16993d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Set parameter limits (optional but recommended)\n",
    "\n",
    "# Adjust these based on your event\n",
    "your_fitter.u0_limits = (0.0, 1.5)           # Impact parameter range\n",
    "your_fitter.t0_limits = (initial_t0 - 100, initial_t0 + 100)  # t0 ± 100 days\n",
    "your_fitter.tE_limits = (5, 200)             # Einstein time range\n",
    "\n",
    "# For finite source models\n",
    "your_fitter.lrho_limits = (-6, 0)\n",
    "\n",
    "# For GP models\n",
    "your_fitter.ln_a_limits = (-5, 15)\n",
    "your_fitter.ln_tau_limits = (-5.5, 7.0)\n",
    "\n",
    "print(\"Parameter limits set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b749e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7: Run optimization first (recommended)\n",
    "\n",
    "print(\"Running optimization to find good starting point...\\n\")\n",
    "your_fitter.fit(method='Nelder-Mead')\n",
    "\n",
    "print(\"\\nOptimized parameters:\")\n",
    "for i, label in enumerate(your_fitter.parameter_labels):\n",
    "    print(f\"  {label}: {your_fitter.p[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ff9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8: Run MCMC sampler\n",
    "\n",
    "print(\"Starting MCMC sampling...\")\n",
    "print(\"This may take several minutes to hours depending on your settings.\\n\")\n",
    "\n",
    "# Run the sampler (optimize_first=False since we already optimized)\n",
    "your_fitter.sample(optimize_first=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLING COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 9: Analyze results\n",
    "\n",
    "print(\"\\nFinal Best-Fit Parameters (Median of Posterior):\")\n",
    "print(\"=\"*70)\n",
    "for i, label in enumerate(your_fitter.parameter_labels):\n",
    "    print(f\"{label}: {your_fitter.p[i]:.6f}\")\n",
    "\n",
    "print(\"\\n\\nOutput Files:\")\n",
    "print(\"=\"*70)\n",
    "output_files = [\n",
    "    f\"{your_fitter.plotprefix}.fit_results (parameter table)\",\n",
    "    f\"{your_fitter.plotprefix}-combined-lightcurve.png (combined light curve)\",\n",
    "    f\"{your_fitter.plotprefix}-lc.png (individual light curves)\",\n",
    "    f\"{your_fitter.plotprefix}-pdist.png (corner plot of posteriors)\",\n",
    "    f\"{your_fitter.plotprefix}-burnin.png (burn-in chains)\",\n",
    "    f\"{your_fitter.plotprefix}-final.png (production chains)\",\n",
    "    f\"{your_fitter.plotprefix}-state-production.npy (final MCMC state)\"\n",
    "]\n",
    "for f in output_files:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Analysis complete! Check the output files for detailed results.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b871b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 10: Display generated plots\n",
    "\n",
    "plot_files = [\n",
    "    (f\"{your_fitter.plotprefix}-combined-lightcurve.png\", \"Combined Light Curve\"),\n",
    "    (f\"{your_fitter.plotprefix}-pdist.png\", \"Posterior Distributions\"),\n",
    "    (f\"{your_fitter.plotprefix}-final.png\", \"MCMC Chains\")\n",
    "]\n",
    "\n",
    "for filename, title in plot_files:\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"\\n{title}:\")\n",
    "        print(\"=\"*70)\n",
    "        display(Image(filename=filename))\n",
    "    else:\n",
    "        print(f\"\\n{title}: File not found ({filename})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96fecc0",
   "metadata": {},
   "source": [
    "## Additional Tips and Best Practices\n",
    "\n",
    "### Choosing Initial Parameters\n",
    "- **u0**: Look at the peak magnification. Higher peaks → smaller u0\n",
    "- **t0**: The time at maximum flux\n",
    "- **tE**: Roughly half the FWHM of the light curve\n",
    "\n",
    "### Model Selection\n",
    "- Start with the simplest PSPL model\n",
    "- Add complexity only if needed (high magnification, visible deviations, etc.)\n",
    "- Use Gaussian Processes if you see correlated residuals\n",
    "- Use mixture models if you have obvious outliers\n",
    "\n",
    "### MCMC Settings\n",
    "- **Testing**: Use `nwalkers=50`, `nsteps_production=500`\n",
    "- **Production**: Use `nwalkers=100-200`, `nsteps_production=2000-5000`\n",
    "- Always run `optimize_first=True` for the first run\n",
    "- Check convergence plots (`*-final.png`) to ensure chains have converged\n",
    "\n",
    "### Interpreting Results\n",
    "- Check the corner plot (`*-pdist.png`) for parameter correlations\n",
    "- Examine residuals in the combined light curve plot\n",
    "- Review the MCMC chains to ensure they've stabilized\n",
    "- The `.fit_results` file contains the 50th percentile and uncertainties\n",
    "\n",
    "### Troubleshooting\n",
    "- **Poor convergence**: Increase `nsteps` or `max_burnin_iterations`\n",
    "- **Bad fit**: Check initial parameters, try optimization first\n",
    "- **Slow performance**: Reduce `nwalkers` or `nsteps_production` for testing\n",
    "- **Unrealistic parameters**: Adjust parameter limits\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "If you use this code, please cite:\n",
    "\n",
    "[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.265134.svg)](https://doi.org/10.5281/zenodo.265134)\n",
    "\n",
    "For more information, see the [GitHub repository](https://github.com/your-username/SingleLensFitter) and the wiki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c0986e",
   "metadata": {},
   "source": [
    "## Decision Guide: Which Features Should I Use?\n",
    "\n",
    "### For Quick Testing and Exploration\n",
    "```python\n",
    "fitter.use_fast_linear_fit = True  # 2-5× faster\n",
    "# Use simple PSPL model only\n",
    "# Reduce nwalkers and nsteps_production\n",
    "```\n",
    "\n",
    "### For Data with Systematic Trends\n",
    "```python\n",
    "# Create eigen lightcurves from reference stars or PCA\n",
    "eigen_lcs = {'Observatory': eigen_array}\n",
    "fitter = SingleLensFitter(data=data, initial_parameters=params, \n",
    "                          eigen_lightcurves=eigen_lcs)\n",
    "```\n",
    "\n",
    "### For High-Magnification Events\n",
    "```python\n",
    "fitter.add_finite_source(lrho=-3.0)  # When u0 < 0.1\n",
    "# or\n",
    "fitter.add_limb_darkening(gamma=0.5, lrho=-2.5)  # For very high mag\n",
    "```\n",
    "\n",
    "### For Correlated Noise\n",
    "```python\n",
    "fitter.add_gaussian_process_model(common=True)\n",
    "# Use when residuals show time-correlated structure\n",
    "```\n",
    "\n",
    "### For Data with Outliers\n",
    "```python\n",
    "fitter.add_mixture_model()\n",
    "# Robust fitting that downweights outliers\n",
    "```\n",
    "\n",
    "### For Variable Stars\n",
    "```python\n",
    "fitter.add_source_variability(params=(0.01, np.pi, 0.0))\n",
    "# or\n",
    "fitter.add_blend_variability(params=(0.01, np.pi, 0.0))\n",
    "```\n",
    "\n",
    "### Example: Production-Quality Fit\n",
    "```python\n",
    "# Comprehensive model for publication\n",
    "fitter = SingleLensFitter(data=multi_obs_data, \n",
    "                          initial_parameters=params,\n",
    "                          eigen_lightcurves=eigen_lcs,\n",
    "                          reference_source='OGLE')\n",
    "fitter.add_limb_darkening(gamma=0.5, lrho=-2.5)\n",
    "fitter.add_gaussian_process_model(common=True)\n",
    "fitter.nwalkers = 100\n",
    "fitter.nsteps_production = 2000\n",
    "fitter.max_burnin_iterations = 50\n",
    "fitter.sample(optimize_first=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577aef9e",
   "metadata": {},
   "source": [
    "## Feature Compatibility Matrix\n",
    "\n",
    "Use this table to understand which features can be used together:\n",
    "\n",
    "| Feature | use_fast_linear_fit | eigen_lightcurves | GP | Mixture | Variability | Finite Source | Limb Darkening |\n",
    "|---------|---------------------|-------------------|----|---------|-----------|--------------|--------------  |\n",
    "| **use_fast_linear_fit** | ✓ | ❌ | ❌ | ❌ | ❌ | ✓ | ✓ |\n",
    "| **eigen_lightcurves** | ❌ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |\n",
    "| **Gaussian Process** | ❌ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |\n",
    "| **Mixture Model** | ❌ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |\n",
    "| **Source/Blend Variability** | ❌ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |\n",
    "| **Finite Source** | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |\n",
    "| **Limb Darkening** | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ (auto) | ✓ |\n",
    "\n",
    "**Key Points**:\n",
    "- `use_fast_linear_fit` is **only** compatible with simple PSPL models (with optional finite source/limb darkening)\n",
    "- `eigen_lightcurves` is compatible with everything **except** `use_fast_linear_fit`\n",
    "- All other features are mutually compatible\n",
    "- Limb darkening automatically includes finite source effects"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
